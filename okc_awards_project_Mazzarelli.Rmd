---
title: 'Analyst Intern, Data Science & Solutions Project'
output: 
    html_document:
        toc: true
        toc_float: true
author: "Matteo Mazzarelli"
date: "`r format(Sys.Date(), '%m/%d/%y')`"
---

```{r set options, include=FALSE}
# DO NOT CHANGE THE LINE BELOW 
knitr::opts_chunk$set(echo = TRUE)
```

``` {css styling, echo=FALSE}

<style>
.tocify {
max-width: 175px !important;
}
</style>

<style>
.main-container {
width: 100%;
max-width: 940px;
margin-left: 40px;
margin-right: auto;
}
</style>

<style>
.red-header {
  color: red;
}
</style>

```

```{r logo, echo = FALSE}

htmltools::img(src = 'https://cdn.nba.com/logos/nba/1610612760/primary/L/logo.svg',
                height = '250px',
                alt = 'logo',
                style = 'position: fixed; bottom: -5px; left: -28px;')
```


# Introduction  

The purpose of this project is to gauge your technical skills and problem solving ability by working through something similar to a real NBA data science project. You will work your way through this R Markdown document, answering questions as you go along. Please begin by adding your name to the "author" key in the YAML header. When you're finished with the document, come back and type your answers into the answer key at the top. Please leave all your work below and have your answers where indicated below as well. Please note that we will be reviewing your code so make it clear, concise and avoid long printouts. Feel free to add in as many new code chunks as you'd like.

Remember that we will be grading the quality of your code and visuals alongside the correctness of your answers. Please try to use the tidyverse as much as possible (instead of base R and explicit loops.)  

**Note:**    

**Throughout this document, any `season` column represents the year each season started. For example, the 2015-16 season will be in the dataset as 2015. For most of the rest of the project, we will refer to a season by just this number (e.g. 2015) instead of the full text (e.g. 2015-16).**   

<h1 class="red-header">Answers</h1>  

## Part 1      

**Question 1:**   

- 1st Team: 25.9 points per game  
- 2nd Team: 23.1 points per game  
- 3rd Team: 20.5 points per game  
- All-Star: 21.6 points per game 

**Question 2:** 3.7 Years  

**Question 3:** 

- Elite: 2 players.  
- All-Star: 1 players.  
- Starter: 10 players.  
- Rotation: 7 players.  
- Roster: 10 players.  
- Out of League: 43 players.  

**Open Ended Modeling Question:** Please show your work and leave all responses below in the document.


## Part 2  

**Question 1:** 28.9%   
**Question 2:** Written question, put answer below in the document.    
**Question 3:** Written question, put answer below in the document.    
  

# Setup and Data    

```{r load data, message = F, warning = F}
library(tidyverse)

awards <- read_csv("awards_data.csv")
player_data <- read_csv("player_stats.csv")
team_data <- read_csv("team_stats.csv")
rebounding_data <- read_csv("team_rebounding_data_22.csv")
```

## Part 1 -- Awards  

In this section, you're going to work with data relating to player awards and statistics. You'll start with some data manipulation questions and work towards building a model to predict broad levels of career success.  

### Question 1  

**QUESTION:** What is the average number of points per game for players in the 2007-2021 seasons who won All NBA First, Second, and Third teams (**not** the All Defensive Teams), as well as for players who were in the All-Star Game (**not** the rookie all-star game)?

```{r}
# Filter the awards dataset for the relevant seasons and awards
awards_filter <- awards %>%
  filter(season %in% 2007:2021,
         `All NBA First Team` == 1 | 
         `All NBA Second Team` == 1 |
         `All NBA Third Team` == 1 |
          all_star_game == 1)

# Join the filtered awards dataset with the player_data dataset
awards_players <- awards_filter %>%
  left_join(player_data, by = join_by(season, nbapersonid))

# Calculate the average points per game for each award category
ppg_1st_team <- awards_players %>%
  filter(`All NBA First Team` == 1) %>%
  summarize(ppg = mean(points / games))

ppg_2nd_team <- awards_players %>%
  filter(`All NBA Second Team` == 1) %>%
  summarize(ppg = mean(points / games))

ppg_3rd_team <- awards_players %>%
  filter(`All NBA Third Team` == 1) %>%
  summarize(ppg = mean(points / games))

ppg_all_star <- awards_players %>%
  filter(all_star_game == 1) %>%
  summarize(ppg = mean(points / games))

# Print the results in the requested format
cat(" 1st Team:", round(ppg_1st_team$ppg, 1), "points per game\n",
"2nd Team:", round(ppg_2nd_team$ppg, 1), "points per game\n",
"3rd Team:", round(ppg_3rd_team$ppg, 1), "points per game\n",
"All-Star:", round(ppg_all_star$ppg, 1), "points per game\n")
```

<span style="color:red">**ANSWER 1:**</span>  

1st Team: 25.9 points per game  
2nd Team: 23.1 points per game  
3rd Team: 20.5 points per game  
All-Star: 21.6 points per game   


### Question 2  

**QUESTION:** What was the average number of years of experience in the league it takes for players to make their first All NBA Selection (1st, 2nd, or 3rd team)? Please limit your sample to players drafted in 2007 or later who did eventually go on to win at least one All NBA selection. For example:

- Luka Doncic is in the dataset as 2 years. He was drafted in 2018 and won his first All NBA award in 2019 (which was his second season).  
- LeBron James is not in this dataset, as he was drafted prior to 2007.  
- Lu Dort is not in this dataset, as he has not received any All NBA honors.  

```{r}
# Filter the awards dataset for players who won at least one All NBA selection and were drafted in 2007 or later
# Only include the earliest observation for any given player
awards_draft <- awards %>%
  filter(`All NBA First Team` == 1 | 
         `All NBA Second Team` == 1 | 
         `All NBA Third Team` == 1) %>%
  group_by(nbapersonid) %>%
  slice_min(season) %>%
  ungroup() %>%
  left_join(player_data, by = join_by(season, nbapersonid)) %>%
  filter(draftyear >= 2007)

# Calculate the average number of years between rookie season and the first All NBA selection season
years_all_nba <- awards_draft %>%
  mutate(years = season - draftyear) %>%
  summarize(avg = mean(years))

# Print the result
cat(round(years_all_nba$avg, 1), "Years\n")
```

<span style="color:red">**ANSWER 2:**</span>  

3.7 Years  


## Data Cleaning Interlude  

You're going to work to create a dataset with a "career outcome" for each player, representing the highest level of success that the player achieved for **at least two** seasons *after his first four seasons in the league* (examples to follow below!). To do this, you'll start with single season level outcomes. On a single season level, the outcomes are:  

- Elite: A player is "Elite" in a season if he won any All NBA award (1st, 2nd, or 3rd team), MVP, or DPOY in that season.    
- All-Star: A player is "All-Star" in a season if he was selected to be an All-Star that season.   
- Starter:  A player is a "Starter" in a season if he started in at least 41 games in the season OR if he played at least 2000 minutes in the season.    
- Rotation:  A player is a "Rotation" player in a season if he played at least 1000 minutes in the season.   
- Roster:  A player is a "Roster" player in a season if he played at least 1 minute for an NBA team but did not meet any of the above criteria.     
- Out of the League: A player is "Out of the League" if he is not in the NBA in that season.   

We need to make an adjustment for determining Starter/Rotation qualifications for a few seasons that didn't have 82 games per team. Assume that there were 66 possible games in the 2011 lockout season and 72 possible games in each of the 2019 and 2020 seasons that were shortened due to covid. Specifically, if a player played 900 minutes in 2011, he **would** meet the rotation criteria because his final minutes would be considered to be 900 * (82/66) = 1118. Please use this math for both minutes and games started, so a player who started 38 games in 2019 or 2020 would be considered to have started 38 * (82/72) = 43 games, and thus would qualify for starting 41. Any answers should be calculated assuming you round the multiplied values to the nearest whole number.

Note that on a season level, a player's outcome is the highest level of success he qualifies for in that season. Thus, since Shai Gilgeous-Alexander was both All-NBA 1st team and an All-Star last year, he would be considered to be "Elite" for the 2022 season, but would still qualify for a career outcome of All-Star if in the rest of his career he made one more All-Star game but no more All-NBA teams. Note this is a hypothetical, and Shai has not yet played enough to have a career outcome.   

Examples:  

- A player who enters the league as a rookie and has season outcomes of Roster (1), Rotation (2), Rotation (3), Roster (4), Roster (5), Out of the League (6+) would be considered "Out of the League," because after his first four seasons, he only has a single Roster year, which does not qualify him for any success outcome.  
- A player who enters the league as a rookie and has season outcomes of Roster (1), Rotation (2), Starter (3), Starter (4), Starter (5), Starter (6), All-Star (7), Elite (8), Starter (9) would be considered "All-Star," because he had at least two seasons after his first four at all-star level of production or higher.  
- A player who enters the league as a rookie and has season outcomes of Roster (1), Rotation (2), Starter (3), Starter (4), Starter (5), Starter (6), Rotation (7), Rotation (8), Roster (9) would be considered a "Starter" because he has two seasons after his first four at a starter level of production. 

<span style="color:red">**CODE USED:**</span>  

```{r}
# Some players have played in different teams in a given season:
# we need to aggregate their stats in order to perform a join with the awards data
# and avoid a many-to-many relationship.
# We only aggregate the stats of relevance to this question and the modeling one
# When aggregating VORP, WS and efg, I take their weighted average over minutes,
# in order to reflect the portion of a season a player has spent playing in a given team.
# Take the last used player name in the dataset to avoid same nbapersonid, different name cases.
players_aggregated <- player_data %>%
  group_by(nbapersonid, season, draftyear) %>%
  summarize(games = sum(games),
            games_start = sum(games_start),
            VORP = sum(VORP*mins)/sum(mins),
            WS = sum(WS*mins)/sum(mins),
            efg = sum(efg*mins)/sum(mins),
            points = sum(points),
            mins = sum(mins),
            .groups = "drop") %>%
  left_join(select(player_data, nbapersonid, player),
            by = join_by(nbapersonid), multiple = "last") %>%
  relocate(player, .after = nbapersonid)

# Prepare the dataset by updating games and minutes for incomplete seasons
season_outcomes <- players_aggregated %>%
  left_join(awards, by = join_by(nbapersonid, season)) %>%
  mutate(games = case_when(
    season %in% c(2019, 2020) ~ round(games * (82/72)),
    season == 2011 ~ round(games * (82/66)),
    TRUE ~ games),
  games_start = case_when(
    season %in% c(2019, 2020) ~ round(games_start * (82/72)),
    season == 2011 ~ round(games_start * (82/66)),
    TRUE ~ games_start),
  mins = case_when(
    season %in% c(2019, 2020) ~ round(mins * (82/72)),
    season == 2011 ~ round(mins * (82/66)),
    TRUE ~ mins)) %>%
  # Create the Outcome column based on the given conditions and assign levels
  mutate(Outcome = case_when(
    `All NBA First Team` == 1 | 
    `All NBA Second Team` == 1 | 
    `All NBA Third Team` == 1 |
    `Most Valuable Player_rk` == 1 |
    `Defensive Player Of The Year_rk` == 1 ~ 1,

    all_star_game == 1 ~ 2,
    
    games_start >= 41 | mins >= 2000 ~ 3,
    
    mins >= 1000 ~ 4,

    mins >= 1 ~ 5,
    
    TRUE ~ 6
  )) %>% # Convert to factors
  mutate(Outcome = factor(Outcome, levels = 1:6,
    labels = c("Elite", "All-Star", "Starter",
    "Rotation", "Roster", "Out of the League")))

# Filter the dataset in order to remove the first 4 seasons in the dataset for each player
# Then, compute the career outcome based on the 2nd highest level any player has obtained
# (after the first 4 seasons in the dataset, which have been filtered out).
# Note that due to lack of pre-2007 season data, this means that career outcomes
# are only accurately computed for players drafted after or in 2007
career_outcomes <- season_outcomes %>%
  arrange(nbapersonid, season) %>%
  group_by(nbapersonid, draftyear) %>%
  slice(-(1:4)) %>%
  arrange(nbapersonid, Outcome) %>%
  summarize(Career = nth(Outcome, 2), .groups = "drop") %>%
  mutate(Career = replace_na(Career, "Out of the League"))
```

### Question 3  

**QUESTION:** There are 73 players in the `player_data` dataset who have 2010 listed as their draft year. How many of those players have a **career** outcome in each of the 6 buckets?  

```{r}
# Filter by draft year and convert factors to numeric for ease of extraction
career_outcomes_2010 <- career_outcomes %>%
  filter(draftyear == 2010) %>%
  mutate(Career = as.numeric(Career))

# Count the number of players who have 2010 as their draft year (should be 73)
draft2010_players <- player_data %>% 
  filter(draftyear == 2010) %>% 
  distinct(nbapersonid) %>% 
  nrow()

# Print the results in the requested format
cat(" Elite:", sum(career_outcomes_2010$Career == 1), "players.\n",
"All-Star:", sum(career_outcomes_2010$Career == 2), "players.\n",
"Starter:", sum(career_outcomes_2010$Career == 3), "players.\n",
"Rotation:", sum(career_outcomes_2010$Career == 4), "players.\n",
"Roster:", sum(career_outcomes_2010$Career == 5), "players.\n",
"Out of League:", draft2010_players - sum(career_outcomes_2010$Career < 6), "players.\n")
```

<span style="color:red">**ANSWER 3:**</span>    

Elite: 2 players.  
All-Star: 1 player.  
Starter: 10 players.  
Rotation: 7 players.  
Roster: 10 players.  
Out of League: 43 players.  

### Open Ended Modeling Question   

In this question, you will work to build a model to predict a player's career outcome based on information up through the first four years of his career. 

This question is intentionally left fairly open ended, but here are some notes and specifications.  

1. We know modeling questions can take a long time, and that qualified candidates will have different levels of experience with "formal" modeling. Don't be discouraged. It's not our intention to make you spend excessive time here. If you get your model to a good spot but think you could do better by spending a lot more time, you can just write a bit about your ideas for future improvement and leave it there. Further, we're more interested in your thought process and critical thinking than we are in specific modeling techniques. Using smart features is more important than using fancy mathematical machinery, and a successful candidate could use a simple regression approach. 

2. You may use any data provided in this project, but please do not bring in any external sources of data. Note that while most of the data provided goes back to 2007, All NBA and All Rookie team voting is only included back to 2011.  

3. A player needs to complete at least three additional seasons after their first four to be considered as having a distinct career outcome for our dataset. (We are using 3+ instead of 2+ just to give each player a little more time to accumulate high level seasons before we classify his career). Because the dataset in this project ends in 2021, this means that a player would need to have had the chance to play in the '21, '20, and '19 seasons after his first four years, and thus his first four years would have been '18, '17, '16, and '15. **For this reason, limit your training data to players who were drafted in or before the 2015 season.** Karl-Anthony Towns was the #1 pick in that season.  

4. Once you build your model, predict on all players who were drafted in 2018-2021 (They have between 1 and 4 seasons of data available and have not yet started accumulating seasons that inform their career outcome).  

5. You can predict a single career outcome for each player, but it's better if you can predict the probability that each player falls into each outcome bucket.    

6. Include, as part of your answer:  
  - A brief written overview of how your model works, targeted towards a decision maker in the front office without a strong statistical background. 
  - What you view as the strengths and weaknesses of your model.  
  - How you'd address the weaknesses if you had more time and or more data.  
  - A ggplot or ggplotly visualization highlighting some part of your modeling process, the model itself, or your results.  
  - Your predictions for Shai Gilgeous-Alexander, Zion Williamson, James Wiseman, and Josh Giddey.  
  - (Bonus!) An html table (for example, see the package `reactable`) containing all predictions for the players drafted in 2019-2021.  

<span style="color:red">**ANSWER:**</span>  

```{r, message = FALSE}
library(tidymodels) # Fundamental package for model fitting
```

Our model will predict each player's Career Outcome based on a limited amount of information we have about other more tenured NBA players. The approach will be based on using each player's available Season Outcomes, as well as a few important statistics (Effective Field Goal Percentage, Total Points) and advanced statistics (Value Over Replacement Player, Win Share). We could have probably made use of more features, but due to the limited size of the training set, we have chosen not to risk overfitting the set too much and settled with only 5 categories of predictors which we deem likely to produce an acceptable result.

Before getting started on the modeling itself, we will re-compute the career outcomes for each player in the dataset with enough information. Based on the requirements, we will take the 3rd best season achieved by a player (in terms of season outcome) after their first 4. It is important to note that with the data at hand, we are not able to accurately calculate a player's career outcome if they have been drafted before 2007, since we do not have a full picture of their seasons.

```{r}
# Re-compute career outcomes based on the 3rd best season after the first 4
# (as specified in the modeling question requirements)
career_outcomes_model <- season_outcomes %>%
  arrange(nbapersonid, season) %>%
  group_by(nbapersonid, draftyear) %>%
  slice(-(1:4)) %>%
  arrange(nbapersonid, Outcome) %>%
  summarize(Career = nth(Outcome, 3), .groups = "drop") %>%
  mutate(Career = replace_na(Career, "Out of the League"))
```

Next, we are going to prepare a dataset which we will use in the modeling stage. This involves preprocessing the data, by performing data cleaning steps, but also by reshaping it, since we will move each player's individual first 4 season statistics from rows to columns, thus making their use in a modeling framework handy. The idea is to use each player's first 4 season outcomes, VORP, WS, points and efg statistics as predictor variables, as well as, of course, the Career Outcome variable as the outcome variable. It is important to note that we chose to only include players drafted in or after 2007 in the dataset, since for them we have complete data.

```{r}
# Prepare the dataset for the modeling stage
# Only keep players drafted in or after 2007, for which we have complete data
# (we only have accurate career outcomes for players drafted post-2017)
model_ds <- season_outcomes %>%
  filter(draftyear >= 2007) %>%
  mutate(across(everything(), ~ replace_na(., 0))) %>%
  arrange(nbapersonid, season) %>%
  group_by(nbapersonid) %>%
  mutate(season_number = row_number()) %>%
  filter(season_number <= 4) %>%
  ungroup() %>%
  pivot_wider(id_cols = c(nbapersonid, player, draftyear),
              names_from = season_number,
              values_from = c(Outcome, VORP, WS, points, efg)) %>%
  left_join(career_outcomes_model, by = join_by(nbapersonid, draftyear))
```

Crucially, since most players drafted after 2018 do not have enough season-by-season information, we will use a robust algorithm to pretty much impute the missing data based on data at our disposal from previous years. This approach is not ideal in a framework where our training set is slightly smaller than our predictor set, but it is reasonable to expect that the method would work reasonably well using datasets containing more seasons. We would usually want our training set to be at least 3-4 times as large as our prediction set, and this is not the case here.

```{r, warning = FALSE, message = FALSE}
set.seed(123) # set random seed for random forest generation

# Perform random forest imputation on the prediction dataset
imputed_ds <- model_ds %>%
  select(-Career) %>%
  missRanger::missRanger(verbose = 0) %>%
  bind_cols(Career = model_ds$Career)
```

Let's proceed to set up our model. We're going to use a method called Random Forest, which is a technique commonly employed in machine learning. This method involves assembling numerous separate decision trees that cooperate to enhance our ability to make accurate predictions. Each decision tree takes in the input data on its own and produces a prediction based on the provided features.

In the context of our analysis, we have data about various statistics related to NBA players. Our goal is to determine which combination of these traits can assist us in predicting whether a player will be successful in the NBA. Think of the random forest model as a team of decision-making specialists (represented by trees) collaborating to tackle a problem. Each tree examines different aspects of the data and forms its own prediction. Subsequently, all these predictions from the trees are brought together to arrive at a final decision. This collective approach reduces the potential errors that any individual tree might make, leading to a more reliable group decision.

```{r}
# Split in training and prediction based on the requirements
# Do not include players with null career outcomes in the training set
training <- imputed_ds %>%
  drop_na(Career) %>%
  filter(draftyear <= 2015)

prediction <- imputed_ds %>%
  filter(draftyear >= 2018)

# Set a tidymodels data recipe
data_recipe <- recipe(Career ~ ., data = imputed_ds) %>%
  update_role(nbapersonid, player, draftyear,
              new_role = "ID")

# Fit a random forest model
fit_rf <- workflow() %>%
  add_recipe(data_recipe) %>%
  add_model(rand_forest(mode = "classification") %>%
  set_engine(engine = "ranger",
             num.threads = 6,
             importance = "impurity")) %>%
  fit(training)
```

Variable Importance within a Random Forest pertains to assessing the significance of input features in contributing to the overall predictive power of the model. It involves analyzing the performance impact of each feature's inclusion and exclusion across the various decision trees. Features that consistently lead to improved accuracy or predictive power across different trees are considered more important. In our case, the most important features turn out to be those that we gather from a player's most recent season in the dataset.

```{r}
# Plot variable importance scores
extract_fit_engine(fit_rf)$variable.importance %>% 
  tibble(Variable = names(.), Importance = .) %>%
  ggplot(aes(reorder(Variable, Importance), Importance, fill = Variable)) +
  geom_col() +
  coord_flip() +
  labs(x = "Feature", y = "Importance",
       title = "Variable Importance scores for random forest model") +
  guides(fill = "none") +
  theme_bw()
```

The distribution of minimal and mean depth for a given variable in a tree provides insights into the hierarchical structure of decision trees within the Random Forest. The depth of a decision tree corresponds to the number of splits it makes before arriving at a prediction. For a specific variable, the minimal depth represents the shallowest level at which the variable is utilized for a decision, while the mean depth is the average level at which the variable is used across all decision trees. If a variable consistently appears at shallow depths in many trees, it signifies that the variable has substantial discriminatory power and is often employed early in decision pathways. Conversely, variables with higher mean depths might play a more minor role in the overall decision-making process.

```{r, message = FALSE}
# Plot each variable's distribution of its minimal depth among the trees of the random forest
randomForestExplainer::plot_min_depth_distribution(
  extract_fit_engine(fit_rf), k = 20,
  main = "Mean and minimal depth for random forest model")
```

We will now look at how the model expects the career of 4 selected players to go.

```{r}
# Compute prediction results
prediction_results <- prediction %>%
  select(nbapersonid, player, draftyear) %>%
  mutate(class = predict(fit_rf, new_data = prediction, "class")$.pred_class,
         predict(fit_rf, new_data = prediction, type = "prob"))

# Show results for the 4 requested players
prediction_results %>%
  select(-nbapersonid) %>%
  filter(str_detect(player, "Shai|Zion|Wiseman|Giddey")) %>%
  mutate(across(where(is.numeric), ~ round(., 2))) %>%
  reactable::reactable(striped = T, outlined = T)
```

- **Shai Gilgeous-Alexander** is expected not to develop into anything more than a Starter, with a probability of around 20% of becoming at least an All-Star. As we know, however, the OKC star has already been voted to be an All-NBA player, which is enough for a season outcome of "Elite".

- **Zion Williamson** has more than a 50% chance of becoming an Elite player according to the model. Zion has shown he can dominate the court when healthy, but many doubt his ability to stay injury-free. I would say that this is well-reflected by the model.

- **James Wiseman** has had a troubled first few seasons in the NBA after being chosen as the 2nd overall pick in the 2020 NBA Draft. The model expects him to develop into a Rotation player, with a slim chance of developing into an All-Star.

- **Josh Giddey** has had a remarkable start to his NBA career and Thunder tenure. However, the model appears to believe that he will quite likely stay a Starter in the long term.

```{r}
# Print out a table containing prediction results
prediction_results %>%
  filter(draftyear >= 2019) %>%
  arrange(class, desc(`.pred_All-Star`)) %>%
  select(-nbapersonid) %>%
  mutate(across(where(is.numeric), ~ round(., 2))) %>%
  reactable::reactable(searchable = T, striped = T, outlined = T)
```

We also show all the players drafted between 2019 and 2021 present in the prediction dataset, together with their individual predictions. The model appears fairly cautious with regard to these 3 draft classes, only assigning "Elite" and "All-Star" outcomes to 4 players.

In conclusion, despite the fairly patchy missing data imputation we have used to perform prediction, and the fact we did not perform any kind of hyperparameter tuning to the tree model, the model seems to produce fairly satisfying and realistic results despite the small training set. This is thanks to the use of a few carefully selected features, which appear to be strong predictors for a player's success in the following years of their development. Furthermore, Random Forest is a good choice for this problem. It's an ensemble method that can handle complex relationships between features, handle non-linearity, and tends to perform well with smaller datasets.

Given more time and a larger dataset, we would however make use of the `team_data.csv` file, which would allow us to incorporate team record (young players may get less of a chance to shine in more successful teams and therefore less playing time, while others may be penalized by carrying their team on their backs and having to settle for less lucrative plays), as well as a more complete set of statistics.

We would also want to think of an alternative approach to imputation for players with fewer than 4 seasons of data at disposal. It would be a good idea to perform separate predictions on player sets that have, for instance, only 2 year of experience. Regardless, the approach used for imputation does not stray too far from what we would ideally have to do.

Finally, we have not shown any evaluation metrics for your model's performance on the training data. Cross-validation or a separate validation dataset would help assess its generalization ability.

## Part 2 -- Predicting Team Stats  

In this section, we're going to introduce a simple way to predict team offensive rebound percent in the next game and then discuss ways to improve those predictions.  
 
### Question 1   

Using the `rebounding_data` dataset, we'll predict a team's next game's offensive rebounding percent to be their average offensive rebounding percent in all prior games. On a single game level, offensive rebounding percent is the number of offensive rebounds divided by their number offensive rebound "chances" (essentially the team's missed shots). On a multi-game sample, it should be the total number of offensive rebounds divided by the total number of offensive rebound chances.    

Please calculate what OKC's predicted offensive rebound percent is for game 81 in the data. That is, use games 1-80 to predict game 81.  

```{r}
# Filter the dataset for OKC's games (team = "OKC")
# And calculate the total number of offensive rebounds and offensive rebound chances for OKC
okc_oreb <- rebounding_data %>%
  filter(team == "OKC", game_number <= 80)

# Predict the offensive rebound percentage for game 81
predicted_rebound_pct <- sum(okc_oreb$offensive_rebounds) / sum(okc_oreb$off_rebound_chances)

# Print the result
cat(label_percent(0.1)(predicted_rebound_pct),"\n")
```

<span style="color:red">**ANSWER 1:**</span>    

28.9% 

### Question 2  

There are a few limitations to the method we used above. For example, if a team has a great offensive rebounder who has played in most games this season but will be out due to an injury for the next game, we might reasonably predict a lower team offensive rebound percent for the next game.  

Please discuss how you would think about changing our original model to better account for missing players. You do not have to write any code or implement any changes, and you can assume you have access to any reasonable data that isn't provided in this project. Try to be clear and concise with your answer.  

<span style="color:red">**ANSWER 2:**</span>  

To better account for missing players and potential changes in team dynamics when predicting offensive rebound percent for the next game, we can consider the following adjustments to our original model:

- Player-Specific Impact: Incorporate individual player statistics related to offensive rebounding when calculating the team's overall offensive rebound percent. If a key offensive rebounder is expected to be absent in the next game, the model should adjust predictions accordingly.

- Player Availability: Include information about player availability for the upcoming game. If a significant offensive rebounder is expected to be out, the model should account for this absence.

- Recent Performance: Give more weight to recent games when calculating the average offensive rebound percent. This would allow the model to capture any recent changes in team dynamics or player availability.

### Question 3  

In question 2, you saw and discussed how to deal with one weakness of the model. For this question, please write about 1-3 other potential weaknesses of the simple average model you made in question 1 and discuss how you would deal with each of them. You may either explain a weakness and discuss how you'd fix that weakness, then move onto the next issue, or you can start by explaining multiple weaknesses with the original approach and discuss one overall modeling methodology you'd use that gets around most or all of them. Again, you do not need to write any code or implement any changes, and you can assume you have access to any reasonable data that isn't provided in this project. Try to be clear and concise with your answer.  

<span style="color:red">**ANSWER 3:**</span>    

Some potential weaknesses of the simple average model used in Question 1 could be addressed as follows:

- Sensitivity to Outliers: The simple average model treats all games equally, regardless of contextual factors. Outlying games, where the team's offensive rebound percent is unusually high or low due to specific circumstances, can disproportionately influence the average. As a solution, we can implement a weighted average approach where recent games are given higher weights. This would help the model adapt to changes over time and reduce the impact of outliers.

- Lack of Contextual Information: The model in Question 1 only considers offensive rebounding percentages without considering other contextual information that could impact rebounding, such as pace of play, playing style, or specific game matchups. To address this, we can incorporate additional features or variables into the model that capture relevant contextual information.

- Ignoring Individual Player Impact: We cannot assume that player availability remains constant, since injuries to key players can significantly impact a team's overall rebounding performance. To address this weakness, we could incorporate a dynamic player impact factor into the model, in order to reflect the influence of key players' presence or absence due to injuries. If a critical offensive rebounder is sidelined, the model could adjust the predicted offensive rebound percent downward to account for the expected decrease in rebounding.

To deal with multiple weaknesses and create a more robust predictive model, we could consider using an approach such as a time series forecasting model. This type of model would inherently take into account the temporal nature of the data, allowing it to capture trends, seasonality, and changes over time. By incorporating relevant contextual features, considering non-linear relationships, and applying techniques like Autoregressive Integrated Moving Averages (*ARIMA*), the model can provide more accurate predictions while accounting for missing players, outliers, and other complexities in the data. This would provide a more sophisticated framework for predicting not just offensive rebounding, but any one statistic we want to inspect.